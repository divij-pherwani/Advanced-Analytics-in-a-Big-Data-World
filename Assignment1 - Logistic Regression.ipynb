{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # to handle data\n",
    "import numpy as np \n",
    "import datetime  # to get the current year value\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df_restore_dtypes(data_array, og_df, exclude):\n",
    "    col_names = og_df.drop(exclude, axis=1).columns.tolist() \n",
    "    arr_df = pd.DataFrame(data_array, columns = col_names)\n",
    "    \n",
    "    bool_columns = og_df.drop(exclude, axis=1).select_dtypes(include='bool').columns.tolist() \n",
    "    int_columns  = og_df.drop(exclude, axis=1).select_dtypes(include='int64').columns.tolist() \n",
    "    str_columns  = og_df.drop(exclude, axis=1).select_dtypes(include='string').columns.tolist() \n",
    "    \n",
    "    arr_df[bool_columns] = arr_df[bool_columns].astype('bool')\n",
    "    arr_df[int_columns]  = arr_df[int_columns].astype('int64')\n",
    "    arr_df[str_columns]  = arr_df[str_columns].astype('string')\n",
    "    \n",
    "    return arr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(true, pred, t=0.5):\n",
    "    pred_binary = [1 if y >= t else 0 for y in pred]\n",
    "    cm = confusion_matrix(true, pred_binary)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print('confusion matrix:')\n",
    "    print(cm)\n",
    "    print()\n",
    "    print('true positives: ', tp)\n",
    "    print('false positives:', fp)\n",
    "    print('true negatives: ', tn)\n",
    "    print('false negatives:', fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m3 = pd.read_csv('data/train_month_3_with_target.csv')\n",
    "test_m3 = pd.read_csv('data/test_month_3.csv')\n",
    "\n",
    "X = train_m3.drop('target', axis=1).to_numpy()\n",
    "y = train_m3['target'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features selected in other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['remainder__visits_distinct_so_areas',\n",
       " 'remainder__prem_fire_car_other_insurance',\n",
       " 'remainder__customer_self_employed',\n",
       " 'remainder__customer_gender',\n",
       " 'remainder__has_insurance_21',\n",
       " 'remainder__customer_age',\n",
       " 'remainder__bal_savings_account_starter',\n",
       " 'remainder__has_current_account',\n",
       " 'remainder__bal_current_account_starter',\n",
       " 'remainder__bal_savings_account',\n",
       " 'remainder__bal_mortgage_loan',\n",
       " 'remainder__bal_personal_loan']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_oldNames = ['visits_distinct_so_areas',\n",
    " 'prem_fire_car_other_insurance',\n",
    " 'customer_self_employed',\n",
    " 'customer_gender',\n",
    " 'has_insurance_21',\n",
    " 'customer_age',\n",
    " 'bal_savings_account_starter',\n",
    " 'has_current_account',\n",
    " 'bal_current_account_starter',\n",
    " 'bal_savings_account',\n",
    " 'bal_mortgage_loan',\n",
    " 'bal_personal_loan']\n",
    "\n",
    "feature_set = [\"remainder__\" + x for x in feature_set_oldNames]\n",
    "feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocces\n",
    "X_train_df = to_df_restore_dtypes(X_train, train_m3, 'target')\n",
    "X_test_df = to_df_restore_dtypes(X_test, train_m3, 'target')\n",
    "\n",
    "data = preprocess(X_train_df, X_test_df, test_m3, 0)\n",
    "X_train_df = data[0]\n",
    "X_test_df = data[1]\n",
    "test_m3 = data[2]\n",
    "\n",
    "# convert to arrays\n",
    "#full_feature_set = list(set(X_train_df.columns.tolist()) - {'remainder__client_id'}) \n",
    "used_features = feature_set\n",
    "\n",
    "X_train_df = X_train_df[used_features]\n",
    "X_train_arr = X_train_df.to_numpy()\n",
    "\n",
    "test_client_id = X_test_df.pop('remainder__client_id')  \n",
    "X_test_df = X_test_df[used_features]\n",
    "X_test_arr = X_test_df.to_numpy()\n",
    "\n",
    "# convert from boolean to int\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "Logistic regression without any sort of class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LogReg = LogisticRegression(solver=\"liblinear\",random_state=42).fit(X_train_arr, y_train)\n",
    "LR_pred_prob = LogReg.predict_proba(X_test_arr)[:,1]\n",
    "LR_pred_class = LogReg.predict(X_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[15214   233]\n",
      " [  461    17]]\n",
      "\n",
      "true positives:  17\n",
      "false positives: 233\n",
      "true negatives:  15214\n",
      "false negatives: 461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = pd.DataFrame(LR_pred_prob, columns = ['prob'])\n",
    "prediction['true'] = y_test.tolist()\n",
    "prediction['pred'] = LR_pred_class\n",
    "\n",
    "sorted_df = prediction.sort_values(by='prob', ascending=False)\n",
    "\n",
    "top_250 = sorted_df.iloc[:250,:]\n",
    "y_prob_250 = top_250['prob'].to_numpy()\n",
    "y_true_250 = top_250['true'].to_numpy()\n",
    "# The top 250 instances are classified as positives\n",
    "y_pred_250 = np.ones(y_true_250.shape)\n",
    "\n",
    "rest = sorted_df.iloc[250:,:]\n",
    "y_prob_rest = rest['prob'].to_numpy()\n",
    "y_true_rest = rest['true'].to_numpy()\n",
    "# Observations not in the top 250 are classified as negatives\n",
    "y_pred_rest = np.zeros(y_true_rest.shape)\n",
    "\n",
    "new_y_true = np.concatenate((y_true_250, y_true_rest), axis=0)\n",
    "new_y_pred = np.concatenate((y_pred_250, y_pred_rest), axis=0)\n",
    "\n",
    "print_confusion_matrix(new_y_true, new_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we perform a grid search for optimal weights for each of the two classes. At each value in parameter \"weights\" we perform a cross validation procedure and then select the parameters with highest score according to the \"roc_auc\" setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    }
   ],
   "source": [
    "weights = np.linspace(0.0,0.99,200)\n",
    "\n",
    "#Creating a dictionary grid for grid search\n",
    "param_grid = {'class_weight': [{0:x, 1:1.0-x} for x in weights]}\n",
    "\n",
    "#Fitting grid search to the train data with 5 folds\n",
    "gridsearch = GridSearchCV(estimator= LogReg, \n",
    "                          param_grid= param_grid,\n",
    "                          cv=StratifiedKFold(), \n",
    "                          n_jobs=-1, \n",
    "                          scoring=\"roc_auc\", \n",
    "                          verbose=2).fit(X_train_arr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7133453386657517 with param: {'class_weight': {0: 0.024874371859296484, 1: 0.9751256281407035}}\n"
     ]
    }
   ],
   "source": [
    "weight_0 = gridsearch.best_params_[\"class_weight\"][0]\n",
    "weight_1 = gridsearch.best_params_[\"class_weight\"][1]\n",
    "\n",
    "print(f'Best score: {gridsearch.best_score_} with param: {gridsearch.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_w = LogisticRegression(solver='liblinear',class_weight = {0:weight_0,1:weight_1}, random_state=10).fit(X_train_arr, y_train) #\n",
    "LR_pred_prob_w = LogReg_w.predict_proba(X_test_arr)[:,1]\n",
    "LR_pred_class_w = LogReg_w.predict(X_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[15225   222]\n",
      " [  450    28]]\n",
      "\n",
      "true positives:  28\n",
      "false positives: 222\n",
      "true negatives:  15225\n",
      "false negatives: 450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_w = pd.DataFrame(LR_pred_prob_w, columns = ['prob'])\n",
    "prediction_w['true'] = y_test.tolist()\n",
    "prediction_w['pred'] = LR_pred_class_w\n",
    "\n",
    "sorted_df_w = prediction_w.sort_values(by='prob', ascending=False)\n",
    "\n",
    "top_250_w = sorted_df_w.iloc[:250,:]\n",
    "y_prob_250_w = top_250_w['prob'].to_numpy()\n",
    "y_true_250_w = top_250_w['true'].to_numpy()\n",
    "\n",
    "# The top 250 instances are classified as positives\n",
    "y_pred_250_w = np.ones(y_true_250_w.shape)\n",
    "\n",
    "rest_w = sorted_df_w.iloc[250:,:]\n",
    "y_prob_rest_w = rest_w['prob'].to_numpy()\n",
    "y_true_rest_w = rest_w['true'].to_numpy()\n",
    "# Observations not in the top 250 are classified as negatives\n",
    "y_pred_rest_w = np.zeros(y_true_rest_w.shape)\n",
    "\n",
    "new_y_true_w = np.concatenate((y_true_250_w, y_true_rest_w), axis=0)\n",
    "new_y_pred_w = np.concatenate((y_pred_250_w, y_pred_rest_w), axis=0)\n",
    "\n",
    "print_confusion_matrix(new_y_true_w, new_y_pred_w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
